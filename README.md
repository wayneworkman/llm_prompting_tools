# LLM Prompting Tools

## Overview

This project offers a collection of tools designed to assist with creating prompts for Large Language Models (LLMs). Each tool focuses on producing tailored prompts that can be easily integrated into LLM workflows.

All content is released under the MIT License.

## Why use these tools?

If you are tired of copy/pasting loads of files, test output, and errors over and over into prompts, these tools are for you.

## Tools

- **dialog_opening:**  
  Generates a comprehensive `prompt.txt` file summarizing a project’s structure and contents, making it easier to start a new dialog with an LLM.

(Additional tools should be added here as they are developed.)

## Contributing

Pull requests are welcome. Before submitting, please note:

- Each tool should reside in its own subdirectory and include corresponding tests.
- If you modify an existing tool, update or add tests as needed.
- If you are unsure how to write tests, consider using an LLM to help generate them.
- Contributions in any programming language are accepted.
- Include a `README.md` with instructions for using your tool.
- You may take credit for your work in your tool’s `README.md`, but all contributions will be released under the MIT License.
- Submissions incompatible with the MIT License will be rejected.
- An LLM-based analysis of your submission should indicate that it is functional, well-intentioned, and meets these requirements.

## Relicensing and Distribution

Most of the content in this project is generated by LLMs and may not be copyrightable in the United States or other jurisdictions.

The project author considers current U.S. laws on LLM-generated materials to be unfortunate. While there are concerns that LLMs are trained on unknown sources of uncertain copyright status, the author points out that the same sources are  utilized by real people to learn new things whom in turn produce copyrightable work. Further, the author’s perspective is that significant human effort, time, experience, and financial resources are invested in producing high-quality LLM-generated output. Companies providing LLMs often state that all rights to generated materials belong to the account holder. Given these factors, the author believes that generated materials deserve protection.

Nevertheless, this project is licensed under MIT. You should review your country’s laws on LLM-produced materials before redistributing the content under other license types.

## Future Ideas

### A Proper Package

Consider evolving this collection into a proper Python package, complete with a `pyproject.toml`, command-line arguments, and/or a configuration file. Improvements could include:

- Cross-platform compatibility
- Versioning
- Detailed installation instructions

### Unit Testing-Focused Tools

Develop tools that target unit testing challenges in various languages. For example:

- One tool could run tests, capture their output, and summarize failing components to feed into an LLM prompt.
- Another might generate new unit tests or provide coverage metrics directly in the prompt.
  
These tools can be language-specific and aim to streamline the test-driven development process.
